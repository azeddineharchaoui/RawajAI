// Service Speech-to-Text CORRIGÃ‰ et compatible mobile/web
export class FixedSpeechService {
  private recognition: any = null
  private isSupported = false
  private isInitialized = false

  constructor() {
    this.initializeSpeechRecognition()
  }

  private initializeSpeechRecognition() {
    try {
      // VÃ©rifier si on est sur web
      if (typeof window === "undefined") {
        console.log("ðŸŽ¤ Pas de window - environnement serveur")
        this.isSupported = false
        return
      }

      // VÃ©rifier le support du navigateur
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition

      if (SpeechRecognition) {
        this.recognition = new SpeechRecognition()
        this.isSupported = true
        this.configureSpeechRecognition()
        this.isInitialized = true
        console.log("ðŸŽ¤ Speech Recognition initialisÃ© avec succÃ¨s")
      } else {
        console.warn("ðŸŽ¤ Speech Recognition non supportÃ© dans ce navigateur")
        this.isSupported = false
        this.isInitialized = true
      }
    } catch (error) {
      console.error("ðŸŽ¤ Erreur initialisation Speech Recognition:", error)
      this.isSupported = false
      this.isInitialized = true
    }
  }

  private configureSpeechRecognition() {
    if (!this.recognition) return

    try {
      // Configuration optimale
      this.recognition.continuous = false
      this.recognition.interimResults = true
      this.recognition.maxAlternatives = 1

      // Langue par dÃ©faut
      this.recognition.lang = "fr-FR"

      console.log("ðŸŽ¤ Configuration Speech Recognition terminÃ©e")
    } catch (error) {
      console.error("ðŸŽ¤ Erreur configuration:", error)
    }
  }

  // MÃ©thode publique pour vÃ©rifier le support
  isSupported(): boolean {
    return this.isSupported && this.isInitialized
  }

  // MÃ©thode pour vÃ©rifier si l'initialisation est terminÃ©e
  isReady(): boolean {
    return this.isInitialized
  }

  async startListening(language = "fr"): Promise<string> {
    // Attendre l'initialisation si nÃ©cessaire
    if (!this.isInitialized) {
      await new Promise((resolve) => setTimeout(resolve, 100))
    }

    if (!this.isSupported) {
      throw new Error("Speech Recognition non supportÃ©")
    }

    return new Promise((resolve, reject) => {
      let finalTranscript = ""
      let interimTranscript = ""
      let hasResult = false

      // Configurer la langue
      this.setLanguage(language)

      // Timeout de sÃ©curitÃ©
      const timeout = setTimeout(() => {
        if (!hasResult) {
          this.recognition?.stop()
          reject(new Error("Timeout - Aucune parole dÃ©tectÃ©e"))
        }
      }, 10000) // 10 secondes max

      // Ã‰vÃ©nements
      this.recognition.onstart = () => {
        console.log("ðŸŽ¤ Ã‰coute dÃ©marrÃ©e...")
      }

      this.recognition.onresult = (event: any) => {
        hasResult = true
        interimTranscript = ""

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript

          if (event.results[i].isFinal) {
            finalTranscript += transcript
          } else {
            interimTranscript += transcript
          }
        }

        console.log("ðŸŽ¤ Transcription en cours:", finalTranscript || interimTranscript)
      }

      this.recognition.onend = () => {
        clearTimeout(timeout)
        console.log("ðŸŽ¤ Ã‰coute terminÃ©e")
        const result = finalTranscript.trim() || interimTranscript.trim()

        if (result && result.length > 0) {
          resolve(result)
        } else {
          reject(new Error("Aucune parole dÃ©tectÃ©e"))
        }
      }

      this.recognition.onerror = (event: any) => {
        clearTimeout(timeout)
        console.error("ðŸŽ¤ Erreur reconnaissance:", event.error)

        let errorMessage = "Erreur de reconnaissance vocale"
        switch (event.error) {
          case "not-allowed":
            errorMessage = "Permission microphone refusÃ©e"
            break
          case "no-speech":
            errorMessage = "Aucune parole dÃ©tectÃ©e"
            break
          case "network":
            errorMessage = "Erreur rÃ©seau"
            break
          default:
            errorMessage = `Erreur: ${event.error}`
        }

        reject(new Error(errorMessage))
      }

      // DÃ©marrer l'Ã©coute
      try {
        this.recognition.start()
      } catch (error) {
        clearTimeout(timeout)
        reject(error)
      }
    })
  }

  stopListening() {
    if (this.recognition) {
      try {
        this.recognition.stop()
        console.log("ðŸŽ¤ ArrÃªt forcÃ© de l'Ã©coute")
      } catch (error) {
        console.warn("ðŸŽ¤ Erreur arrÃªt:", error)
      }
    }
  }

  private setLanguage(language: string) {
    if (!this.recognition) return

    const languageCodes = {
      fr: "fr-FR",
      en: "en-US",
      ar: "ar-SA",
      darija: "ar-MA",
    }

    try {
      this.recognition.lang = languageCodes[language as keyof typeof languageCodes] || "fr-FR"
      console.log(`ðŸŽ¤ Langue configurÃ©e: ${this.recognition.lang}`)
    } catch (error) {
      console.warn("ðŸŽ¤ Erreur configuration langue:", error)
    }
  }

  // MÃ©thode alternative avec MediaRecorder (plus compatible)
  async startRecordingWithMediaRecorder(): Promise<Blob> {
    try {
      console.log("ðŸŽ¤ Demande permission microphone...")
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
        },
      })

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: "audio/webm;codecs=opus",
      })
      const audioChunks: Blob[] = []

      return new Promise((resolve, reject) => {
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunks.push(event.data)
          }
        }

        mediaRecorder.onstop = () => {
          console.log("ðŸŽ¤ Enregistrement terminÃ©, crÃ©ation du blob...")
          const audioBlob = new Blob(audioChunks, { type: "audio/webm" })

          // ArrÃªter tous les tracks
          stream.getTracks().forEach((track) => {
            track.stop()
            console.log("ðŸŽ¤ Track arrÃªtÃ©:", track.kind)
          })

          resolve(audioBlob)
        }

        mediaRecorder.onerror = (event) => {
          console.error("ðŸŽ¤ Erreur MediaRecorder:", event)
          stream.getTracks().forEach((track) => track.stop())
          reject(new Error("Erreur d'enregistrement"))
        }

        // DÃ©marrer l'enregistrement
        mediaRecorder.start(1000) // Chunk toutes les secondes
        console.log("ðŸŽ¤ Enregistrement MediaRecorder dÃ©marrÃ©")

        // ArrÃªter aprÃ¨s 10 secondes max
        setTimeout(() => {
          if (mediaRecorder.state === "recording") {
            console.log("ðŸŽ¤ ArrÃªt automatique aprÃ¨s 10s")
            mediaRecorder.stop()
          }
        }, 10000)
      })
    } catch (error) {
      console.error("ðŸŽ¤ Erreur accÃ¨s microphone:", error)
      throw new Error("Impossible d'accÃ©der au microphone. VÃ©rifiez les permissions.")
    }
  }

  // Transcription avec API gratuite (simulation amÃ©liorÃ©e)
  async transcribeAudio(audioBlob: Blob): Promise<string> {
    try {
      console.log("ðŸŽ¤ Transcription audio, taille:", audioBlob.size)

      // Simulation rÃ©aliste de transcription
      // Dans un vrai projet, utiliser Whisper API ou Google Speech
      await new Promise((resolve) => setTimeout(resolve, 2000)) // Simule le traitement

      const realisticTranscriptions = [
        "Comment optimiser mon stock de produits ?",
        "Aide-moi Ã  faire des prÃ©visions pour le mois prochain",
        "Quels sont les KPIs importants pour ma supply chain ?",
        "Comment rÃ©duire mes coÃ»ts de transport ?",
        "Analyse mes donnÃ©es de vente s'il te plaÃ®t",
        "Je veux amÃ©liorer mon taux de service client",
        "Peux-tu m'expliquer la mÃ©thode EOQ ?",
        "Comment calculer mon stock de sÃ©curitÃ© ?",
        "Quelles sont les meilleures pratiques en logistique ?",
        "Comment amÃ©liorer mes prÃ©visions de demande ?",
      ]

      const randomTranscription = realisticTranscriptions[Math.floor(Math.random() * realisticTranscriptions.length)]
      console.log("ðŸŽ¤ Transcription simulÃ©e:", randomTranscription)

      return randomTranscription
    } catch (error) {
      console.error("ðŸŽ¤ Erreur transcription:", error)
      throw new Error("Impossible de transcrire l'audio")
    }
  }

  // VÃ©rifier les permissions microphone
  async checkMicrophonePermission(): Promise<boolean> {
    try {
      const result = await navigator.permissions.query({ name: "microphone" as PermissionName })
      console.log("ðŸŽ¤ Permission microphone:", result.state)
      return result.state === "granted"
    } catch (error) {
      console.warn("ðŸŽ¤ Impossible de vÃ©rifier les permissions:", error)
      return false
    }
  }
}
